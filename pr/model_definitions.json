{
  "assume_beta": "@model function assume_beta()\n    a ~ Beta(2, 2)\nend\n\n@register assume_beta()",
  "assume_dirichlet": "@model function assume_dirichlet()\n    a ~ Dirichlet([1.0, 5.0])\nend\n\n@register assume_dirichlet()",
  "demo_assume_index_observe": "@model function demo_assume_index_observe(\n    x = [1.5, 2.0],\n    ::Type{TV} = Vector{Float64},\n) where {TV}\n    # `assume` with indexing and `observe`\n    s = TV(undef, length(x))\n    for i in eachindex(s)\n        s[i] ~ InverseGamma(2, 3)\n    end\n    m = TV(undef, length(x))\n    for i in eachindex(m)\n        m[i] ~ Normal(0, sqrt(s[i]))\n    end\n    x ~ MvNormal(m, Diagonal(s))\nend\n\n@register demo_assume_index_observe()",
  "demo_assume_matrix_observe_matrix_index": "@model function demo_assume_matrix_observe_matrix_index(\n    x = transpose([1.5 2.0;]),\n    ::Type{TV} = Array{Float64},\n) where {TV}\n    n = length(x)\n    d = n \u00f7 2\n    s ~ reshape(product_distribution(fill(InverseGamma(2, 3), n)), d, 2)\n    s_vec = vec(s)\n    m ~ MvNormal(zeros(n), Diagonal(s_vec))\n\n    x[:, 1] ~ MvNormal(m, Diagonal(s_vec))\nend\n\n@register demo_assume_matrix_observe_matrix_index()",
  "demo_assume_multivariate_observe": "@model function demo_assume_multivariate_observe(x = [1.5, 2.0])\n    # Multivariate `assume` and `observe`\n    s ~ product_distribution([InverseGamma(2, 3), InverseGamma(2, 3)])\n    m ~ MvNormal(zero(x), Diagonal(s))\n    x ~ MvNormal(m, Diagonal(s))\nend\n@register demo_assume_multivariate_observe()",
  "demo_assume_multivariate_observe_literal": "@model function demo_assume_multivariate_observe_literal()\n    # multivariate `assume` and literal `observe`\n    s ~ product_distribution([InverseGamma(2, 3), InverseGamma(2, 3)])\n    m ~ MvNormal(zeros(2), Diagonal(s))\n    [1.5, 2.0] ~ MvNormal(m, Diagonal(s))\nend\n\n@register demo_assume_multivariate_observe_literal()",
  "demo_assume_observe_literal": "@model function demo_assume_observe_literal()\n    # univariate `assume` and literal `observe`\n    s ~ InverseGamma(2, 3)\n    m ~ Normal(0, sqrt(s))\n    1.5 ~ Normal(m, sqrt(s))\n    2.0 ~ Normal(m, sqrt(s))\nend\n\n@register demo_assume_observe_literal()",
  "demo_assume_submodel_observe_index_literal": "@model function _prior_dot_assume(::Type{TV} = Vector{Float64}) where {TV}\n    s = TV(undef, 2)\n    s .~ InverseGamma(2, 3)\n    m = TV(undef, 2)\n    m ~ product_distribution(Normal.(0, sqrt.(s)))\n    return s, m\nend\n\n@model function demo_assume_submodel_observe_index_literal()\n    # Submodel prior\n    priors ~ to_submodel(_prior_dot_assume(), false)\n    s, m = priors\n    1.5 ~ Normal(m[1], sqrt(s[1]))\n    2.0 ~ Normal(m[2], sqrt(s[2]))\nend\n\n@register demo_assume_submodel_observe_index_literal()",
  "demo_dot_assume_observe": "@model function demo_dot_assume_observe(\n    x = [1.5, 2.0],\n    ::Type{TV} = Vector{Float64},\n) where {TV}\n    # `dot_assume` and `observe`\n    s = TV(undef, length(x))\n    m = TV(undef, length(x))\n    s .~ InverseGamma(2, 3)\n    m ~ product_distribution(Normal.(0, sqrt.(s)))\n    x ~ MvNormal(m, Diagonal(s))\nend\n\n@register demo_dot_assume_observe()",
  "demo_dot_assume_observe_index": "@model function demo_dot_assume_observe_index(\n    x = [1.5, 2.0],\n    ::Type{TV} = Vector{Float64},\n) where {TV}\n    # `dot_assume` and `observe` with indexing\n    s = TV(undef, length(x))\n    s .~ InverseGamma(2, 3)\n    m = TV(undef, length(x))\n    m ~ product_distribution(Normal.(0, sqrt.(s)))\n    for i in eachindex(x)\n        x[i] ~ Normal(m[i], sqrt(s[i]))\n    end\nend\n\n@register demo_dot_assume_observe_index()",
  "demo_dot_assume_observe_index_literal": "@model function demo_dot_assume_observe_index_literal(\n    ::Type{TV} = Vector{Float64},\n) where {TV}\n    # `dot_assume` and literal `observe` with indexing\n    s = TV(undef, 2)\n    m = TV(undef, 2)\n    s .~ InverseGamma(2, 3)\n    m ~ product_distribution(Normal.(0, sqrt.(s)))\n\n    1.5 ~ Normal(m[1], sqrt(s[1]))\n    2.0 ~ Normal(m[2], sqrt(s[2]))\nend\n\n@register demo_dot_assume_observe_index_literal()",
  "demo_dot_assume_observe_matrix_index": "@model function demo_dot_assume_observe_matrix_index(\n    x = transpose([1.5 2.0;]),\n    ::Type{TV} = Vector{Float64},\n) where {TV}\n    s = TV(undef, length(x))\n    s .~ InverseGamma(2, 3)\n    m = TV(undef, length(x))\n    m ~ product_distribution(Normal.(0, sqrt.(s)))\n    x[:, 1] ~ MvNormal(m, Diagonal(s))\nend\n\n@register demo_dot_assume_observe_matrix_index()",
  "assume_lkjcholu": "@model function assume_lkjcholu()\n    a ~ LKJCholesky(5, 1.0, 'U')\nend\n\n@register assume_lkjcholu()",
  "demo_dot_assume_observe_submodel": "@model function _likelihood_multivariate_observe(s, m, x)\n    return x ~ MvNormal(m, Diagonal(s))\nend\n\n@model function demo_dot_assume_observe_submodel(\n    x = [1.5, 2.0],\n    ::Type{TV} = Vector{Float64},\n) where {TV}\n    s = TV(undef, length(x))\n    s .~ InverseGamma(2, 3)\n    m = TV(undef, length(x))\n    m ~ product_distribution(Normal.(0, sqrt.(s)))\n\n    # Submodel likelihood\n    # With to_submodel, we have to have a left-hand side variable to\n    # capture the result, so we just use a dummy variable\n    _ignore ~ to_submodel(_likelihood_multivariate_observe(s, m, x))\nend\n\n@register demo_dot_assume_observe_submodel()",
  "dot_assume": "@model function dot_assume(::Type{TV} = Vector{Float64}) where {TV}\n    a = TV(undef, 5)\n    a .~ Normal()\nend\n\n@register dot_assume()",
  "dot_observe": "@model function dot_observe(x = [1.5, 2.0, 2.5])\n    a ~ Normal()\n    x .~ Normal(a)\nend\n\n@register dot_observe()",
  "dppl_gauss_unknown": "n = 10_000\ns = abs(rand()) + 0.5\ny = randn() .+ s * randn(n)\n\n@model function dppl_gauss_unknown(y)\n    N = length(y)\n    m ~ Normal(0, 1)\n    s ~ truncated(Cauchy(0, 5); lower=0)\n    y ~ filldist(Normal(m, s), N)\nend\n\n@register dppl_gauss_unknown(y)",
  "dppl_high_dim_gauss": "@model function dppl_high_dim_gauss(D)\n    m ~ filldist(Normal(0, 1), D)\nend\n\n@register dppl_high_dim_gauss(10_000)",
  "dppl_naive_bayes": "using MLDatasets: MNIST\nusing MultivariateStats: fit, PCA, transform\n\n# Load MNIST images and labels\nfeatures = MNIST(split=:train).features\nnrows, ncols, nimages = size(features)\nimage_raw = Float64.(reshape(features, (nrows * ncols, nimages)))\nlabels = MNIST(split=:train).targets .+ 1\nC = 10 # Number of labels\n\n# Preprocess the images by reducing dimensionality\nD = 40\npca = fit(PCA, image_raw; maxoutdim=D)\nimage = transform(pca, image_raw)\n\n# Take only the first 1000 images and vectorise\nN = 1000\nimage_subset = image[:, 1:N]'\nimage_vec = vec(image_subset[:, :])\nlabels = labels[1:N]\n\n@model dppl_naive_bayes(image_vec, labels, C, D) = begin\n    m ~ filldist(Normal(0, 10), C, D)\n    image_vec ~ MvNormal(vec(m[labels, :]), I)\nend\n\n@register dppl_naive_bayes(image_vec, labels, C, D)",
  "dynamic_constraint": "@model function dynamic_constraint()\n    a ~ Normal()\n    b ~ truncated(Normal(); lower = a)\nend\n\n@register dynamic_constraint()",
  "multiple_constraints_same_var": "@model function multiple_constraints_same_var(::Type{TV} = Vector{Float64}) where {TV}\n    x = TV(undef, 5)\n    x[1] ~ Normal()\n    x[2] ~ InverseGamma(2, 3)\n    x[3] ~ truncated(Normal(), -5, 20)\n    x[4:5] ~ Dirichlet([1.0, 2.0])\nend\n\n@register multiple_constraints_same_var()",
  "multithreaded": "#=\nMost models in ADTests are run with 1 thread. This model is run with 2 threads\nto properly demonstrate the compatibility with multithreaded observe\nstatements. See `main.jl` for more information.\n=#\n\n@model function multithreaded(x)\n    a ~ Normal()\n    Threads.@threads for i in eachindex(x)\n        x[i] ~ Normal(a)\n    end\nend\n\n@register multithreaded([1.5, 2.0, 2.5, 1.5, 2.0, 2.5])",
  "n010": "@model function n010(::Type{TV} = Vector{Float64}) where {TV}\n    a = TV(undef, 10)\n    for i in eachindex(a)\n        a[i] ~ Normal()\n    end\nend\n\n@register n010()",
  "assume_mvnormal": "@model function assume_mvnormal()\n    a ~ MvNormal([0.0, 0.0], [1.0 0.5; 0.5 1.0])\nend\n\n@register assume_mvnormal()",
  "n050": "@model function n050(::Type{TV} = Vector{Float64}) where {TV}\n    a = TV(undef, 50)\n    for i in eachindex(a)\n        a[i] ~ Normal()\n    end\nend\n\n@register n050()",
  "n100": "@model function n100(::Type{TV} = Vector{Float64}) where {TV}\n    a = TV(undef, 100)\n    for i in eachindex(a)\n        a[i] ~ Normal()\n    end\nend\n\n@register n100()",
  "n500": "@model function n500(::Type{TV} = Vector{Float64}) where {TV}\n    a = TV(undef, 500)\n    for i in eachindex(a)\n        a[i] ~ Normal()\n    end\nend\n\n@register n500()",
  "observe_index": "@model function observe_index(x = [1.5, 2.0, 2.5])\n    a ~ Normal()\n    for i in eachindex(x)\n        x[i] ~ Normal(a)\n    end\nend\n\n@register observe_index()",
  "observe_literal": "@model function observe_literal()\n    a ~ Normal()\n    1.5 ~ Normal(a)\nend\n\n@register observe_literal()",
  "observe_multivariate": "@model function observe_multivariate(\n    x = [1.5, 2.0, 2.5],\n    ::Type{TV} = Vector{Float64},\n) where {TV}\n    a = TV(undef, length(x))\n    a .~ Normal()\n    x ~ MvNormal(a, I)\nend\n\n@register observe_multivariate()",
  "observe_submodel": "@model function inner2(x, a)\n    x ~ Normal(a)\nend\n@model function observe_submodel(x = 1.5)\n    a ~ Normal()\n    _ignore ~ to_submodel(inner2(x, a))\nend\n\n@register observe_submodel()",
  "pdb_eight_schools_centered": "J = 8\ny = [28, 8, -3, 7, -1, 1, 18, 12]\nsigma = [15, 10, 16, 11, 9, 11, 10, 18]\n\n@model function pdb_eight_schools_centered(J, y, sigma)\n    mu ~ Normal(0, 5)\n    tau ~ truncated(Cauchy(0, 5); lower = 0)\n    theta = Vector{Float64}(undef, J)\n    for i = 1:J\n        theta[i] ~ Normal(mu, tau)\n        y[i] ~ Normal(theta[i], sigma[i])\n    end\nend\n\n@register pdb_eight_schools_centered(J, y, sigma)",
  "pdb_eight_schools_noncentered": "J = 8\ny = [28, 8, -3, 7, -1, 1, 18, 12]\nsigma = [15, 10, 16, 11, 9, 11, 10, 18]\n\n@model function pdb_eight_schools_noncentered(J, y, sigma)\n    mu ~ Normal(0, 5)\n    tau ~ truncated(Cauchy(0, 5); lower = 0)\n    theta_trans = Vector{Float64}(undef, J)\n    for i = 1:J\n        theta_trans[i] ~ Normal(0, 1)\n        theta = theta_trans[i] * tau + mu\n        y[i] ~ Normal(theta, sigma[i])\n    end\nend\n\n@register pdb_eight_schools_noncentered(J, y, sigma)",
  "assume_normal": "@model function assume_normal()\n    a ~ Normal()\nend\n\n@register assume_normal()",
  "assume_submodel": "@model function inner1()\n    return a ~ Normal()\nend\n@model function assume_submodel()\n    a ~ to_submodel(inner1())\n    x ~ Normal(a)\nend\n\n@register assume_submodel()",
  "assume_wishart": "@model function assume_wishart()\n    a ~ Wishart(7, [1.0 0.5; 0.5 1.0])\nend\n\n@register assume_wishart()",
  "control_flow": "#= \nThis model illustrates dynamic control flow inside a model that depends on the\nvalue of a random variable. This will cause problems with ReverseDiff's\ncompiled tapes, as a tape compiled at a given value of `a` may not be\nappropriate for a different value of `a`.\n\nTo make sure that the table correctly reflects this issue, the preparation for\nthe gradient is carried out at a value of `a > 0`, and the gradient is\nevaluated at a value of `a < 0`. See `main.jl` for more information.\n=#\n\n@model function control_flow()\n    a ~ Normal()\n    if a > 0\n        b ~ Normal()\n    else\n        b ~ Beta(2, 2)\n    end\nend\n\n@register control_flow()",
  "demo_assume_dot_observe": "@model function demo_assume_dot_observe(x = [1.5, 2.0])\n    # `assume` and `dot_observe`\n    s ~ InverseGamma(2, 3)\n    m ~ Normal(0, sqrt(s))\n    x .~ Normal(m, sqrt(s))\nend\n\n@register demo_assume_dot_observe()",
  "demo_assume_dot_observe_literal": "@model function demo_assume_dot_observe_literal()\n    # `assume` and literal `dot_observe`\n    s ~ InverseGamma(2, 3)\n    m ~ Normal(0, sqrt(s))\n    [1.5, 2.0] .~ Normal(m, sqrt(s))\nend\n\n@register demo_assume_dot_observe_literal()"
}