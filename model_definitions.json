{
  "assume_dirichlet": "@model function assume_dirichlet()\n    a ~ Dirichlet([1.0, 5.0])\nend\n\n@register assume_dirichlet()",
  "assume_lkjcholu": "@model function assume_lkjcholu()\n    a ~ LKJCholesky(5, 1.0, 'U')\nend\n\n@register assume_lkjcholu()",
  "dot_observe": "@model function dot_observe(x = [1.5, 2.0, 2.5])\n    a ~ Normal()\n    x .~ Normal(a)\nend\n\n@register dot_observe()",
  "dynamic_constraint": "@model function dynamic_constraint()\n    a ~ Normal()\n    b ~ truncated(Normal(); lower = a)\nend\n\n@register dynamic_constraint()",
  "multiple_constraints_same_var": "@model function multiple_constraints_same_var(::Type{TV} = Vector{Float64}) where {TV}\n    x = TV(undef, 5)\n    x[1] ~ Normal()\n    x[2] ~ InverseGamma(2, 3)\n    x[3] ~ truncated(Normal(), -5, 20)\n    x[4:5] ~ Dirichlet([1.0, 2.0])\nend\n\n@register multiple_constraints_same_var()",
  "multithreaded": "#=\nMost models in ADTests are run with 1 thread. This model is run with 2 threads\nto properly demonstrate the compatibility with multithreaded observe\nstatements. See `main.jl` for more information.\n=#\n\n@model function multithreaded(x)\n    a ~ Normal()\n    Threads.@threads for i in eachindex(x)\n        x[i] ~ Normal(a)\n    end\nend\n\n@register multithreaded([1.5, 2.0, 2.5, 1.5, 2.0, 2.5])",
  "n010": "@model function n010(::Type{TV} = Vector{Float64}) where {TV}\n    a = TV(undef, 10)\n    for i in eachindex(a)\n        a[i] ~ Normal()\n    end\nend\n\n@register n010()",
  "n050": "@model function n050(::Type{TV} = Vector{Float64}) where {TV}\n    a = TV(undef, 50)\n    for i in eachindex(a)\n        a[i] ~ Normal()\n    end\nend\n\n@register n050()",
  "n100": "@model function n100(::Type{TV} = Vector{Float64}) where {TV}\n    a = TV(undef, 100)\n    for i in eachindex(a)\n        a[i] ~ Normal()\n    end\nend\n\n@register n100()",
  "n500": "@model function n500(::Type{TV} = Vector{Float64}) where {TV}\n    a = TV(undef, 500)\n    for i in eachindex(a)\n        a[i] ~ Normal()\n    end\nend\n\n@register n500()",
  "observe_index": "@model function observe_index(x = [1.5, 2.0, 2.5])\n    a ~ Normal()\n    for i in eachindex(x)\n        x[i] ~ Normal(a)\n    end\nend\n\n@register observe_index()",
  "observe_literal": "@model function observe_literal()\n    a ~ Normal()\n    1.5 ~ Normal(a)\nend\n\n@register observe_literal()",
  "assume_mvnormal": "@model function assume_mvnormal()\n    a ~ MvNormal([0.0, 0.0], [1.0 0.5; 0.5 1.0])\nend\n\n@register assume_mvnormal()",
  "observe_multivariate": "@model function observe_multivariate(\n    x = [1.5, 2.0, 2.5],\n    ::Type{TV} = Vector{Float64},\n) where {TV}\n    a = TV(undef, length(x))\n    a .~ Normal()\n    x ~ MvNormal(a, I)\nend\n\n@register observe_multivariate()",
  "observe_submodel": "@model function inner2(x, a)\n    x ~ Normal(a)\nend\n@model function observe_submodel(x = 1.5)\n    a ~ Normal()\n    _ignore ~ to_submodel(inner2(x, a))\nend\n\n@register observe_submodel()",
  "pdb_eight_schools_centered": "J = 8\ny = [28, 8, -3, 7, -1, 1, 18, 12]\nsigma = [15, 10, 16, 11, 9, 11, 10, 18]\n\n@model function pdb_eight_schools_centered(J, y, sigma)\n    mu ~ Normal(0, 5)\n    tau ~ truncated(Cauchy(0, 5); lower = 0)\n    theta = Vector{Float64}(undef, J)\n    for i = 1:J\n        theta[i] ~ Normal(mu, tau)\n        y[i] ~ Normal(theta[i], sigma[i])\n    end\nend\n\n@register pdb_eight_schools_centered(J, y, sigma)",
  "pdb_eight_schools_noncentered": "J = 8\ny = [28, 8, -3, 7, -1, 1, 18, 12]\nsigma = [15, 10, 16, 11, 9, 11, 10, 18]\n\n@model function pdb_eight_schools_noncentered(J, y, sigma)\n    mu ~ Normal(0, 5)\n    tau ~ truncated(Cauchy(0, 5); lower = 0)\n    theta_trans = Vector{Float64}(undef, J)\n    for i = 1:J\n        theta_trans[i] ~ Normal(0, 1)\n        theta = theta_trans[i] * tau + mu\n        y[i] ~ Normal(theta, sigma[i])\n    end\nend\n\n@register pdb_eight_schools_noncentered(J, y, sigma)",
  "assume_normal": "@model function assume_normal()\n    a ~ Normal()\nend\n\n@register assume_normal()",
  "assume_submodel": "@model function inner1()\n    return a ~ Normal()\nend\n@model function assume_submodel()\n    a ~ to_submodel(inner1())\n    x ~ Normal(a)\nend\n\n@register assume_submodel()",
  "assume_wishart": "@model function assume_wishart()\n    a ~ Wishart(7, [1.0 0.5; 0.5 1.0])\nend\n\n@register assume_wishart()",
  "control_flow": "#= \nThis model illustrates dynamic control flow inside a model that depends on the\nvalue of a random variable. This will cause problems with ReverseDiff's\ncompiled tapes, as a tape compiled at a given value of `a` may not be\nappropriate for a different value of `a`.\n\nTo make sure that the table correctly reflects this issue, the preparation for\nthe gradient is carried out at a value of `a > 0`, and the gradient is\nevaluated at a value of `a < 0`. See `main.jl` for more information.\n=#\n\n@model function control_flow()\n    a ~ Normal()\n    if a > 0\n        b ~ Normal()\n    else\n        b ~ Beta(2, 2)\n    end\nend\n\n@register control_flow()",
  "demo_dot_assume_observe": "@model function demo_dot_assume_observe(\n    x = [1.5, 2.0],\n    ::Type{TV} = Vector{Float64},\n) where {TV}\n    # `dot_assume` and `observe`\n    s = TV(undef, length(x))\n    m = TV(undef, length(x))\n    s .~ InverseGamma(2, 3)\n    m ~ product_distribution(Normal.(0, sqrt.(s)))\n\n    x ~ MvNormal(m, Diagonal(s))\n    return (; s = s, m = m, x = x, logp = getlogp(__varinfo__))\nend\n\n@register demo_dot_assume_observe()",
  "demo_dot_assume_observe_index": "@model function demo_dot_assume_observe_index(\n    x = [1.5, 2.0],\n    ::Type{TV} = Vector{Float64},\n) where {TV}\n    # `dot_assume` and `observe` with indexing\n    s = TV(undef, length(x))\n    s .~ InverseGamma(2, 3)\n    m = TV(undef, length(x))\n    m ~ product_distribution(Normal.(0, sqrt.(s)))\n    for i in eachindex(x)\n        x[i] ~ Normal(m[i], sqrt(s[i]))\n    end\n\n    return (; s = s, m = m, x = x, logp = getlogp(__varinfo__))\nend\n\n@register demo_dot_assume_observe_index()",
  "dot_assume": "@model function dot_assume(::Type{TV} = Vector{Float64}) where {TV}\n    a = TV(undef, 5)\n    a .~ Normal()\nend\n\n@register dot_assume()"
}